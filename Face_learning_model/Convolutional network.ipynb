{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288 125 94\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70,  download_if_missing = True, resize=1, color=False)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "X = lfw_people.data\n",
    "Y = lfw_people.target\n",
    "\n",
    "print(n_samples,h,w)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(862, 11750)\n",
      "(862,)\n",
      "(426, 11750)\n",
      "(426,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [5],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [5],\n",
       "       [6],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [1],\n",
       "       [4],\n",
       "       [6],\n",
       "       [2],\n",
       "       [6],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [5],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [1],\n",
       "       [4],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [0],\n",
       "       [5],\n",
       "       [6],\n",
       "       [3],\n",
       "       [5],\n",
       "       [0],\n",
       "       [6],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [2],\n",
       "       [0],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [4],\n",
       "       [6],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [6],\n",
       "       [1],\n",
       "       [1],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [6],\n",
       "       [6],\n",
       "       [2],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [6],\n",
       "       [1],\n",
       "       [5],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [6],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [6],\n",
       "       [0],\n",
       "       [1],\n",
       "       [6],\n",
       "       [1],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [4],\n",
       "       [6],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [6],\n",
       "       [0],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [4],\n",
       "       [2],\n",
       "       [5],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [6],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [6],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [6],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [6],\n",
       "       [5],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [6],\n",
       "       [1],\n",
       "       [4],\n",
       "       [6],\n",
       "       [6],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [6],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [6],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [6],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [2],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [6],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [6],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [5],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [6],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [6],\n",
       "       [2],\n",
       "       [3],\n",
       "       [6],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [5],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [6],\n",
       "       [6],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [6],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [5],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "#x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],h,w,1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train/255\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],h,w,1)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test/255\n",
    "\n",
    "y_train = np.array([[x] for x in y_train])\n",
    "y_test = np.array([[x] for x in y_test])\n",
    "\n",
    "#y_train = np.where(y_train == 1, 1, 0)\n",
    "#y_test = np.where(y_test == 1, 1, 0)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-322-dbba410ed2d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "#One-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "classes = {\n",
    "  1: 'target1'\n",
    "}\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "y_train = to_categorical(y_train,num_classes)\n",
    "y_test = to_categorical(y_test,num_classes)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-308-b2236f296892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "model2 = models.Sequential()\n",
    "\n",
    "# keras.layers.Conv2D(filters, kernel_size... filter is how many filters (windows of sub pixel set) kernel is the window size eg: 3x3 pixels\n",
    "model2.add(layers.Conv2D(32, (3,3), activation='relu',input_shape=(125, 94,1)))\n",
    "model2.add(layers.MaxPool2D((2,2))) # Max Pooling to reduce the spatial dimensions of the output volume. pool_size: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal)\n",
    "model2.add(layers.Conv2D(64,(3,3),activation='relu')) # does not need input_shape, since it gets it from previous layer\n",
    "model2.add(layers.MaxPool2D((2,2)))\n",
    "model2.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model2.add(layers.Flatten()) # rewrite tensor to single vector of values\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(10, activation='softmax')) # softmax is good for output layer because Softmax outputs probabilities range. The range will 0 to 1, and the sum of all the probabilities will be equal to one. If the softmax function used for multi-classification model it returns the probabilities of each class and the target class will have the high probability.\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', # loss is how to meassure how wrong the model is on its predictions\n",
    "             optimizer='rmsprop', # \"stochastic gradient descent\" is a way to tell algorithm how to improve\n",
    "             metrics=['accuracy'], # what do we care about in our model\n",
    "             )\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         epochs=8,\n",
    "         verbose=True,\n",
    "         batch_size=64,\n",
    "         validation_split=0.1) # checking periodically how well we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        [(None, 125, 94, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 123, 92, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_114 (MaxPoolin (None, 61, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 59, 44, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_115 (MaxPoolin (None, 29, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 27, 20, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_116 (MaxPoolin (None, 13, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 33280)             0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 4096)              136318976 \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 140,786,641\n",
      "Trainable params: 140,786,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of samples 862 is not divisible by steps 5. Please change the number of steps to a value that can consume all the samples",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-296-b0878c202cd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         validation_split=validation_split)\n\u001b[0m\u001b[0;32m    215\u001b[0m     dist_utils.validate_callbacks(input_callbacks=callbacks,\n\u001b[0;32m    216\u001b[0m                                   optimizer=model.optimizer)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\distribute\\distributed_training_utils.py\u001b[0m in \u001b[0;36mprocess_batch_and_step_size\u001b[1;34m(strategy, inputs, batch_size, steps_per_epoch, mode, validation_split)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;31m# relax the constraint to consume all the training samples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     steps_per_epoch, batch_size = get_input_params(\n\u001b[1;32m--> 469\u001b[1;33m         strategy, num_samples, steps_per_epoch, batch_size, mode=mode)\n\u001b[0m\u001b[0;32m    470\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\distribute\\distributed_training_utils.py\u001b[0m in \u001b[0;36mget_input_params\u001b[1;34m(distribution_strategy, num_samples, steps, batch_size, mode)\u001b[0m\n\u001b[0;32m    543\u001b[0m                          \u001b[1;34m'steps %s. Please change the number of steps to a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                          'value that can consume all the samples' % (\n\u001b[1;32m--> 545\u001b[1;33m                              num_samples, steps))\n\u001b[0m\u001b[0;32m    546\u001b[0m       \u001b[0mglobal_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of samples 862 is not divisible by steps 5. Please change the number of steps to a value that can consume all the samples"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "img_input = tf.keras.layers.Input(shape=(125, 94,1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64,3, activation='relu')(img_input)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "#x = tf.keras.layers.Conv2D(512, 3, activation='relu')(x) #d\n",
    "#x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "#x = tf.keras.layers.Conv2D(512, 3, activation='relu')(x) #d2\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "#x = tf.keras.layers.Dense(4096, activation='relu')(x) #d\n",
    "x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.5)(x) #0.2\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(img_input,output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.0005),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, steps_per_epoch=5, epochs=80, validation_data=y_train, validation_steps=7, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 862 samples\n",
      "Epoch 1/8\n",
      "862/862 [==============================] - 0s 467us/sample - loss: 2.8989 - accuracy: 0.3039\n",
      "Epoch 2/8\n",
      "862/862 [==============================] - 0s 159us/sample - loss: 1.7029 - accuracy: 0.4246\n",
      "Epoch 3/8\n",
      "862/862 [==============================] - 0s 155us/sample - loss: 1.5214 - accuracy: 0.4722\n",
      "Epoch 4/8\n",
      "862/862 [==============================] - 0s 156us/sample - loss: 1.4735 - accuracy: 0.4675\n",
      "Epoch 5/8\n",
      "862/862 [==============================] - 0s 157us/sample - loss: 1.3546 - accuracy: 0.5429\n",
      "Epoch 6/8\n",
      "862/862 [==============================] - 0s 154us/sample - loss: 1.2391 - accuracy: 0.5731\n",
      "Epoch 7/8\n",
      "862/862 [==============================] - 0s 168us/sample - loss: 1.1428 - accuracy: 0.6009\n",
      "Epoch 8/8\n",
      "862/862 [==============================] - 0s 154us/sample - loss: 1.1172 - accuracy: 0.6195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e35baeb1c8>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu)) \n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy']) \n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 250us/sample - loss: 1.1816 - accuracy: 0.6667\n",
      "1.181574351910694 0.6666667\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test) #Calculate validation loss and validation accuracy\n",
    "print(val_loss, val_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rasmu\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rasmu\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Convolutional_network.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Convolutional_network.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Convolutional_network.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('Convolutional_network.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (426, 125, 1) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-325-2f7c68c50e38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2681\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2682\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2683\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2684\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2685\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1601\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5669\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5671\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5672\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 690\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (426, 125, 1) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
