{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140 50 37 3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=100,  download_if_missing = False, resize=0.4, color=True)\n",
    "n_samples, h, w, rgb = lfw_people.images.shape\n",
    "\n",
    "X = lfw_people.data\n",
    "Y = lfw_people.target\n",
    "\n",
    "print(n_samples,h,w,rgb)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763, 5550)\n",
      "(763,)\n",
      "(377, 5550)\n",
      "(377,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "#x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],h,w,3)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train/255\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],h,w,3)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test/255\n",
    "\n",
    "plt.imshow(x_test[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_13 (Reshape)         (None, 50, 37, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 50, 37, 12)        324       \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 50, 37, 12)        36        \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 50, 37, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 25, 19, 24)        10368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 25, 19, 24)        72        \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 25, 19, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 13, 10, 32)        27648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 13, 10, 32)        96        \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 13, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 200)               832000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 200)               600       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 873,154\n",
      "Trainable params: 872,618\n",
      "Non-trainable params: 536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape(input_shape=(50,37,3,), target_shape=(50, 37, 3)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(kernel_size=3, filters=12, padding='same', use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(kernel_size=6, filters=24, padding='same', use_bias=False, strides=2),\n",
    "    tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(kernel_size=6, filters=32, padding='same', use_bias=False, strides=2),\n",
    "    tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(200, use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-eee77e426291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m history = model.fit(x_train, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n\u001b[1;32m---> 11\u001b[1;33m                     validation_data=y_train, validation_steps=1, callbacks=[lr_decay_callback])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    593\u001b[0m         use_multiprocessing=use_multiprocessing)\n\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m       (val_x, val_y,\n\u001b[0;32m    597\u001b[0m        \u001b[0mval_sample_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_validation_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 109 #7\n",
    "EPOCHS = 10\n",
    "steps_per_epoch = 763//BATCH_SIZE\n",
    "\n",
    "def lr_decay(epoch):\n",
    "    return 0.01 * math.pow(0.666, epoch)\n",
    "\n",
    "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\n",
    "\n",
    "history = model.fit(x_train, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
    "                    validation_data=y_train, validation_steps=1, callbacks=[lr_decay_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (426, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-5d5c8efd48ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Calculate validation loss and validation accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m   def predict(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2487\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2489\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m       sample_weights, _, _ = training_utils.handle_partial_sample_weights(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    782\u001b[0m         raise ValueError('You are passing a target array of shape ' +\n\u001b[0;32m    783\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m                          \u001b[1;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m                          \u001b[1;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                          \u001b[1;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are passing a target array of shape (426, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test) #Calculate validation loss and validation accuracy\n",
    "print(val_loss, val_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (108,) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-cc3003cb8e3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2681\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2682\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2683\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2684\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2685\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1601\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5669\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5671\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5672\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 690\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (108,) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
